{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "import os\n",
    "import os.path\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def space_str(layer):\n",
    "\tlua_str = \"\"\n",
    "\tfor i in range(0,layer):\n",
    "\t\tlua_str += '\\t'\n",
    "\treturn lua_str\n",
    " \n",
    "def dic_to_lua_str(data,layer=0):\n",
    "\td_type = type(data)\n",
    "\tif  d_type is str :\n",
    "\t\treturn \"'\" + data + \"'\"\n",
    "\telif d_type is bool:\n",
    "\t\tif data:\n",
    "\t\t\treturn 'true'\n",
    "\t\telse:\n",
    "\t\t\treturn 'false'\n",
    "\telif d_type in (int,float):\n",
    "\t\treturn str(data)\n",
    "\telif d_type is list:\n",
    "\t\tlua_str = \"{\\n\"\n",
    "\t\tlua_str += space_str(layer+1)\n",
    "\t\tfor i in range(0,len(data)):\n",
    "\t\t\tlua_str += dic_to_lua_str(data[i],layer+1)\n",
    "\t\t\tif i < len(data)-1:\n",
    "\t\t\t\tlua_str += ','\n",
    "\t\tlua_str += '\\n'\n",
    "\t\tlua_str += space_str(layer)\n",
    "\t\tlua_str +=  '}'\n",
    "\t\treturn lua_str\n",
    "\telif d_type is dict:\n",
    "\t\tlua_str = ''\n",
    "\t\tlua_str += \"\\n\"\n",
    "\t\tlua_str += space_str(layer)\n",
    "\t\tlua_str += \"{\\n\"\n",
    "\t\tdata_len = len(data)\n",
    "\t\tdata_count = 0\n",
    "\t\tfor k,v in data.items():\n",
    "\t\t\tdata_count += 1\n",
    "\t\t\tlua_str += space_str(layer+1)\n",
    "\t\t\tif type(k) in (int,float):\n",
    "\t\t\t\tlua_str += '[' + str(k) + ']'\n",
    "\t\t\telse:\n",
    "\t\t\t\tlua_str += k \n",
    "\t\t\tlua_str += ' = '\n",
    "\t\t\ttry:\n",
    "\t\t\t\tlua_str += dic_to_lua_str(v,layer +1)\n",
    "\t\t\t\tif data_count < data_len:\n",
    "\t\t\t\t\tlua_str += ',\\n'\n",
    " \n",
    "\t\t\texcept Exception as e:\n",
    "\t\t\t\tprint( 'error in ',k,v)\n",
    "\t\t\t\traise\n",
    "\t\tlua_str += ',\\n'\n",
    "\t\tlua_str += space_str(layer)\n",
    "\t\tlua_str += '}'\n",
    "\t\treturn lua_str\n",
    "\telse:\n",
    "\t\tprint( d_type , 'is error')\n",
    "\t\treturn None\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_depth(data):\n",
    "    root = {}\n",
    "    keys = list(data.keys())\n",
    "    cols = [str.split(c,'.') for c in keys]\n",
    "    for i,c in enumerate(cols):\n",
    "        base_ds = root\n",
    "        for j,d in enumerate(c):\n",
    "            if d not in base_ds:\n",
    "                base_ds[d] = {}\n",
    "            if j < len(c)-1:\n",
    "                base_ds = base_ds[d]\n",
    "            else:\n",
    "                base_ds[c[-1]] = data[keys[i]]\n",
    "    return root\n",
    "\n",
    "\n",
    "for fn in os.listdir('./csv'):\n",
    "    if fn.find('.csv') > 0:\n",
    "        df = pd.read_csv(f\"./csv/{fn}\")\n",
    "\n",
    "        if fn.find(\".const.\")>0:\n",
    "            data = {r[0]:r[1] for r in df.values}\n",
    "            with open(f'./json/{fn[:-4]}.json', 'w') as f:\n",
    "                json.dump(data, f, ensure_ascii=True, indent='\\t')\n",
    "            continue\n",
    "\n",
    "        dtype = df.iloc[0]\n",
    "        df = df[2:]\n",
    "\n",
    "        for c in df.columns:\n",
    "            if dtype[c] == 'int':\n",
    "                df[c] = df[c].apply(int)\n",
    "            if dtype[c] == 'float':\n",
    "                df[c] = df[c].astype(float)\n",
    "            if dtype[c] == 'list':\n",
    "                df[c] = df[c].apply(eval)\n",
    "            if dtype[c] == 'dict':\n",
    "                df[c] = df[c].apply(eval)\n",
    "\n",
    "        if fn.find('.list.') > 0:\n",
    "            data = [to_depth(data) for data in list(df.T.to_dict().values())]\n",
    "            with open(f'./json/{fn[:-4]}.json', 'w') as f:\n",
    "                json.dump(data, f, ensure_ascii=True, indent='\\t')\n",
    "                f.close()\n",
    "            with open(f'./lua/{fn[:-4]}.lua', 'w') as f:\n",
    "                f.write('local config = '+ dic_to_lua_str(data) + '\\n return config')\n",
    "                f.close()\n",
    "        else:\n",
    "            df.set_index(df.columns[0],inplace=True)\n",
    "            data = {key:to_depth(data) for key,data in df.T.to_dict().items()}\n",
    "            with open(f'./json/{fn[:-4]}.json', 'w') as f:\n",
    "                json.dump(data, f, ensure_ascii=True, indent='\\t')\n",
    "                f.close()\n",
    "            with open(f'./lua/{fn[:-4]}.lua', 'w') as f:\n",
    "                f.write('local config = '+ dic_to_lua_str(data) + '\\n return config')\n",
    "                f.close()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "45c0494e61cc75dcfba547a54ff51f241998206744d34dcca317142fc479e387"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
